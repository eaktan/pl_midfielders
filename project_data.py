# -*- coding: utf-8 -*-
"""Project Data

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DJoRohR5g7qREWujqRNWjcQkLN9Rl-c-
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import numpy as np

# --- 1. DATA LOADING AND INITIAL CLEANING ---
df = pd.read_csv('pl_midfielders_master_combined.csv')
actual_names = df.iloc[0].values
df.columns = [actual_names[i] if "Unnamed" in df.columns[i] else df.columns[i] for i in range(len(df.columns))]
df = df.drop(df.index[0]).reset_index(drop=True)

# --- 2. NUMERIC CONVERSION & FILTERING ---
metrics = ['90s Played', 'npxG', 'xAG', 'KP', 'PPA', 'Tkl+Int', 'Blocks', 'Clr', 'PrgDist', '1/3', 'PrgP']
for col in metrics:
    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

# 1000 Minutes Threshold (11.11 full 90s)
core_df = df[df['90s Played'] >= (1000/90)].copy()

# --- 3. FEATURE ENGINEERING (PER 90) ---
core_df['npxG_p90'] = core_df['npxG'] / core_df['90s Played']
core_df['xAG_p90'] = core_df['xAG'] / core_df['90s Played']
core_df['KP_p90'] = core_df['KP'] / core_df['90s Played']
core_df['PPA_p90'] = core_df['PPA'] / core_df['90s Played']
core_df['TklInt_p90'] = core_df['Tkl+Int'] / core_df['90s Played']
core_df['Blocks_p90'] = core_df['Blocks'] / core_df['90s Played']
core_df['Clr_p90'] = core_df['Clr'] / core_df['90s Played']
core_df['PrgDist_p90'] = core_df['PrgDist'] / core_df['90s Played']
core_df['FinalThird_p90'] = core_df['1/3'] / core_df['90s Played']
core_df['PrgP_p90'] = core_df['PrgP'] / core_df['90s Played']

# --- 4. INDEX GENERATION (0-100) ---
scaler = MinMaxScaler()
off_cols = ['npxG_p90', 'xAG_p90', 'KP_p90', 'PPA_p90']
def_cols = ['TklInt_p90', 'Blocks_p90', 'Clr_p90']
prg_cols = ['PrgDist_p90', 'FinalThird_p90', 'PrgP_p90']

core_df['Offense_Index'] = scaler.fit_transform(core_df[off_cols]).mean(axis=1) * 100
core_df['Defense_Index'] = scaler.fit_transform(core_df[def_cols]).mean(axis=1) * 100
core_df['Progression_Index'] = scaler.fit_transform(core_df[prg_cols]).mean(axis=1) * 100

# --- 5. ARCHETYPE CLASSIFICATION ---
# Required for grouping later
core_df['Off_Pct'] = core_df['Offense_Index'].rank(pct=True)
core_df['Def_Pct'] = core_df['Defense_Index'].rank(pct=True)
core_df['Prg_Pct'] = core_df['Progression_Index'].rank(pct=True)

def label_archetype(row):
    if row['Off_Pct'] > 0.7 and row['Prg_Pct'] > 0.7:
        return "Creative Engine"
    elif row['Def_Pct'] > 0.7 and row['Prg_Pct'] > 0.7:
        return "Deep-Lying Progressor"
    elif row['Def_Pct'] > 0.7 and row['Off_Pct'] < 0.4:
        return "Midfield Anchor"
    elif row['Off_Pct'] > 0.4 and row['Def_Pct'] > 0.4 and row['Prg_Pct'] > 0.4:
        return "Modern Box-to-Box"
    else:
        return "System Rotational"

core_df['Archetype'] = core_df.apply(label_archetype, axis=1)

# --- 6. LONGITUDINAL TRENDS & T-TESTS ---
seasonal_trends = core_df.groupby('Season')[['Offense_Index', 'Defense_Index', 'Progression_Index']].mean().reset_index()

# T-Test Table (Era Comparison)
s_start, s_end = '2017-2018', '2024-2025'
print(f"{'Metric':<15} | {'Start Mean':<12} | {'End Mean':<12} | {'% Change':<10} | {'P-Value'}")
print("-" * 70)
for metric in ['Offense_Index', 'Defense_Index', 'Progression_Index']:
    m1 = core_df[core_df['Season'] == s_start][metric]
    m2 = core_df[core_df['Season'] == s_end][metric]
    p_val = stats.ttest_ind(m1, m2)[1]
    pct_change = ((m2.mean() - m1.mean()) / m1.mean()) * 100
    print(f"{metric:<15} | {m1.mean():<12.2f} | {m2.mean():<12.2f} | {pct_change:<+9.1f}% | {p_val:.4f}")

# --- 7. ARCHETYPE ANALYSIS & CHI-SQUARE ---
archetype_counts = core_df.groupby(['Season', 'Archetype']).size().unstack(fill_value=0)
start_row, end_row = archetype_counts.loc[s_start], archetype_counts.loc[s_end]

comparison_summary = pd.DataFrame({
    'Start (17-18)': start_row,
    'End (24-25)': end_row,
    'Net Change': end_row - start_row,
    '% Growth': ((end_row - start_row) / start_row) * 100
})

# Individual Chi-Square for archetypes
for arch in archetype_counts.columns:
    obs = [[start_row[arch], start_row.sum()-start_row[arch]], [end_row[arch], end_row.sum()-end_row[arch]]]
    comparison_summary.loc[arch, 'P-Value'] = round(stats.chi2_contingency(obs)[1], 4)

print("\n--- ARCHETYPE FINAL COMPARISON ---")
print(comparison_summary)

# --- 8. TOP PLAYERS RANKING ---
def calculate_archetype_score(row):
    if row['Archetype'] == "Creative Engine": return row['Offense_Index'] + row['Progression_Index']
    elif row['Archetype'] == "Deep-Lying Progressor": return row['Defense_Index'] + row['Progression_Index']
    elif row['Archetype'] == "Midfield Anchor": return row['Defense_Index']
    elif row['Archetype'] == "Modern Box-to-Box": return row['Offense_Index'] + row['Defense_Index'] + row['Progression_Index']
    return 0

core_df['Performance_Score'] = core_df.apply(calculate_archetype_score, axis=1)
top_players = core_df[core_df['Archetype'] != "System Rotational"].sort_values(['Season', 'Archetype', 'Performance_Score'], ascending=[True, True, False]).groupby(['Season', 'Archetype']).head(1)

# --- 9. VISUALIZATIONS ---
# 1. Index Trends
plt.figure(figsize=(10, 5))
sns.lineplot(data=seasonal_trends, x='Season', y='Offense_Index', label='Offense', marker='o')
sns.lineplot(data=seasonal_trends, x='Season', y='Defense_Index', label='Defense', marker='s')
sns.lineplot(data=seasonal_trends, x='Season', y='Progression_Index', label='Progression', marker='^')
plt.title('PL Midfielders Index Evolution')
plt.xticks(rotation=45)
plt.savefig('index_trends.png')

# 2. Archetype Evolution
plot_data = archetype_counts.reset_index().melt(id_vars='Season', var_name='Archetype', value_name='Count')
plt.figure(figsize=(12, 6))
sns.lineplot(data=plot_data, x='Season', y='Count', hue='Archetype', marker='o', linewidth=2)
plt.title('Evolution of Midfielder Archetypes')
plt.xticks(rotation=45)
plt.savefig('archetype_evolution.png')

# 3. Radar Chart: Xhaka vs Tielemans
radar_metrics = ['npxG_p90', 'xAG_p90', 'KP_p90', 'PPA_p90', 'TklInt_p90', 'PrgP_p90', 'FinalThird_p90']
radar_labels = ['npxG', 'xAG', 'KP', 'PPA', 'Tkl+Int', 'PrgP', '1/3']
radar_scaler = MinMaxScaler()
radar_data = core_df.copy()
radar_data[radar_metrics] = radar_scaler.fit_transform(radar_data[radar_metrics]) * 100

xhaka = radar_data[(radar_data['Player'].str.contains('Xhaka')) & (radar_data['Season'] == '2017-2018')].iloc[0]
tielemans = radar_data[(radar_data['Player'].str.contains('Tielemans')) & (radar_data['Season'] == '2024-2025')].iloc[0]

angles = np.linspace(0, 2 * np.pi, len(radar_labels), endpoint=False).tolist()
angles += angles[:1]

def get_v(row):
    v = row[radar_metrics].values.tolist()
    return v + v[:1]

fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))
ax.plot(angles, get_v(xhaka), color='red', label='Xhaka (17-18)')
ax.fill(angles, get_v(xhaka), color='red', alpha=0.1)
ax.plot(angles, get_v(tielemans), color='blue', label='Tielemans (24-25)')
ax.fill(angles, get_v(tielemans), color='blue', alpha=0.1)
ax.set_thetagrids(np.degrees(angles[:-1]), radar_labels)
plt.legend(loc='upper right')
plt.savefig('radar_comparison.png')

plt.show()

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors

# 1. LOAD AND PRE-PROCESS THE DATASET
# Handling the specific header format of the Premier League dataset
df = pd.read_csv('pl_midfielders_master_combined.csv')
actual_names = df.iloc[0].values
df.columns = [actual_names[i] if "Unnamed" in df.columns[i] else df.columns[i] for i in range(len(df.columns))]
df = df.drop(df.index[0]).reset_index(drop=True)

# 2. NUMERIC CONVERSION & PER 90 NORMALIZATION
# We select the core metrics that define a player's functional profile
metrics = ['90s Played', 'npxG', 'xAG', 'KP', 'PPA', 'Tkl+Int', 'Blocks', 'Clr', 'PrgDist', '1/3', 'PrgP']
for col in metrics:
    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

# Filter for Core Players (at least 1000 minutes / ~11.1 games) to ensure statistical reliability
core_df = df[df['90s Played'] >= (1000/90)].copy()

# Feature Engineering: Convert raw totals to 'Per 90' stats (Industrial Engineering "Standardization")
# This ensures that players with more minutes don't look "better" just because of volume
metrics_p90 = ['npxG_p90', 'xAG_p90', 'KP_p90', 'PPA_p90', 'TklInt_p90', 'Blocks_p90', 'Clr_p90', 'PrgDist_p90', 'FinalThird_p90', 'PrgP_p90']
core_df['npxG_p90'] = core_df['npxG'] / core_df['90s Played']
core_df['xAG_p90'] = core_df['xAG'] / core_df['90s Played']
core_df['KP_p90'] = core_df['KP'] / core_df['90s Played']
core_df['PPA_p90'] = core_df['PPA'] / core_df['90s Played']
core_df['TklInt_p90'] = core_df['Tkl+Int'] / core_df['90s Played']
core_df['Blocks_p90'] = core_df['Blocks'] / core_df['90s Played']
core_df['Clr_p90'] = core_df['Clr'] / core_df['90s Played']
core_df['PrgDist_p90'] = core_df['PrgDist'] / core_df['90s Played']
core_df['FinalThird_p90'] = core_df['1/3'] / core_df['90s Played']
core_df['PrgP_p90'] = core_df['PrgP'] / core_df['90s Played']

# 3. STANDARDIZATION (Critical for KNN Distance calculation - Following Recitation 8)
# We use StandardScaler to ensure all metrics contribute equally to the "Similarity Score"
# Otherwise, 'PrgDist' (values in 100s) would dominate 'xAG' (values in 0.1s)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(core_df[metrics_p90])

# 4. K-NEAREST NEIGHBORS MODEL (Following Week 9)
# We use K=6 to get the player themselves + the top 5 most similar matches
# We use Euclidean Distance as the metric for "closeness" in the statistical space
knn_model = NearestNeighbors(n_neighbors=6, metric='euclidean')
knn_model.fit(X_scaled)

def find_similar_players(player_name, season_year):
    """
    Finds the top functional replacements based on statistical similarity.
    This acts as a 'Replacement Analysis' tool for a football system.
    """
    try:
        # 1. Locate the player in our processed DataFrame
        target = core_df[(core_df['Player'].str.contains(player_name)) & (core_df['Season'] == season_year)]
        if target.empty:
            return f"Player {player_name} not found in season {season_year}."

        target_idx = target.index[0]
        # 2. Get the row position relative to the scaled matrix
        row_pos = core_df.index.get_loc(target_idx)

        # 3. Calculate Euclidean distances to all other players
        distances, indices = knn_model.kneighbors(X_scaled[row_pos].reshape(1, -1))

        # 4. Format and return results
        matches = core_df.iloc[indices[0]].copy()
        matches['Similarity_Distance'] = distances[0] # Lower distance = More similar profile

        return matches[['Player', 'Season', 'Squad', 'Similarity_Distance']]

    except Exception as e:
        return f"Error: {str(e)}"

# --- EXAMPLES OF SIMILARITY SEARCH ---

# Search 1: The Creative Engine (Prime KDB)
print("Finding 'Functional Replacements' for Prime De Bruyne (2019-20):")
print(find_similar_players('Kevin De Bruyne', '2019-2020'))

# Search 2: The Volume Distributor (Prime Xhaka)
print("\nFinding 'Functional Replacements' for Prime Jorginho (2017-18):")
print(find_similar_players('Jorginho', '2019-2020'))

# Search 3: The Defensive Anchor (Prime Ndidi)
print("\nFinding 'Functional Replacements' for Prime Declan Rice (2017-18):")
print(find_similar_players('Declan Rice', '2023-2024'))